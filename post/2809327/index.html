<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><title>k8s网络小探 | snoopy</title><meta name=viewport content="width=device-width,minimum-scale=1"><meta name=description content="容器网络 在说k8s的网络之前，先熟悉下容器的网络模式。
 docker会在宿主机启动一张网卡 docker0 容器通过Veth Pair 连接容器和docker0，Veth Pair相当于网线 docker0 在容器通信的过程中相当于二层交换机 容器会有默认路由指向docker0 当一个容器试图连接到另外一个宿主机时，首先经过 docker0 网桥出现在宿主机上。然后根据宿主机路由规则路由  #使用以下命令查看网桥的连接情况 [root@rbtnode1 ~]# brctl show bridge name bridge id STP enabled interfaces br-5bc39396abe2 8000.024219350061 no veth1a289de veth3504d23 docker0 8000.0242d50f88b5 no veth210c0a2 ... [root@rbtnode1 ~]# ip ad | grep veth 16: vethwe-datapath@vethwe-bridge: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1376 qdisc noqueue master datapath state UP group default 17: vethwe-bridge@vethwe-datapath: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1376 qdisc noqueue master weave state UP group default 2631: veth210c0a2@if2630: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master docker0 state UP group default 2682: veth3504d23@if2681: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master br-5bc39396abe2 state UP group default ##这里可以看到我们宿主机存在一个虚拟网卡 veth3504d23 ，他一端连接的是docker0，另一端则连接的是容器的eth0 ##其他的容器在创建的时候也会发生同样的事 ##相当于启动容器后，会有一“网线”，连接docker0和容器，由于都连接同一个交换机，默认情况下，各个容器间可以直接互通 容器的通信示意图（源自张磊）：k8s网络的发展 在docker的默认配置下，容器的网络没法处理跨主机网络的互相通信。为了解决跨主机通信的问题，社区出现了一些方案 flannel UDP 模式 而 UDP 模式，是 Flannel 项目最早支持的一种方式，也是性能最差的一种模式，如今已被弃用，但是对我们理解集群的网络还是有帮助的 该模式的主要通信过程如下"><meta name=generator content="Hugo 0.83.1"><meta name=ROBOTS content="NOINDEX, NOFOLLOW"><link rel=stylesheet href=/dingtalk.pub/ananke/dist/main.css_5c99d70a7725bacd4c701e995b969fea.css><meta property="og:title" content="k8s网络小探"><meta property="og:description" content="容器网络 在说k8s的网络之前，先熟悉下容器的网络模式。
 docker会在宿主机启动一张网卡 docker0 容器通过Veth Pair 连接容器和docker0，Veth Pair相当于网线 docker0 在容器通信的过程中相当于二层交换机 容器会有默认路由指向docker0 当一个容器试图连接到另外一个宿主机时，首先经过 docker0 网桥出现在宿主机上。然后根据宿主机路由规则路由  #使用以下命令查看网桥的连接情况 [root@rbtnode1 ~]# brctl show bridge name bridge id STP enabled interfaces br-5bc39396abe2 8000.024219350061 no veth1a289de veth3504d23 docker0 8000.0242d50f88b5 no veth210c0a2 ... [root@rbtnode1 ~]# ip ad | grep veth 16: vethwe-datapath@vethwe-bridge: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1376 qdisc noqueue master datapath state UP group default 17: vethwe-bridge@vethwe-datapath: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1376 qdisc noqueue master weave state UP group default 2631: veth210c0a2@if2630: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master docker0 state UP group default 2682: veth3504d23@if2681: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master br-5bc39396abe2 state UP group default ##这里可以看到我们宿主机存在一个虚拟网卡 veth3504d23 ，他一端连接的是docker0，另一端则连接的是容器的eth0 ##其他的容器在创建的时候也会发生同样的事 ##相当于启动容器后，会有一“网线”，连接docker0和容器，由于都连接同一个交换机，默认情况下，各个容器间可以直接互通 容器的通信示意图（源自张磊）：k8s网络的发展 在docker的默认配置下，容器的网络没法处理跨主机网络的互相通信。为了解决跨主机通信的问题，社区出现了一些方案 flannel UDP 模式 而 UDP 模式，是 Flannel 项目最早支持的一种方式，也是性能最差的一种模式，如今已被弃用，但是对我们理解集群的网络还是有帮助的 该模式的主要通信过程如下"><meta property="og:type" content="article"><meta property="og:url" content="dingtalk.pub/post/2809327/"><meta property="article:section" content="post"><meta property="article:published_time" content="2019-10-11T15:52:55+00:00"><meta property="article:modified_time" content="2019-10-11T15:52:55+00:00"><meta itemprop=name content="k8s网络小探"><meta itemprop=description content="容器网络 在说k8s的网络之前，先熟悉下容器的网络模式。
 docker会在宿主机启动一张网卡 docker0 容器通过Veth Pair 连接容器和docker0，Veth Pair相当于网线 docker0 在容器通信的过程中相当于二层交换机 容器会有默认路由指向docker0 当一个容器试图连接到另外一个宿主机时，首先经过 docker0 网桥出现在宿主机上。然后根据宿主机路由规则路由  #使用以下命令查看网桥的连接情况 [root@rbtnode1 ~]# brctl show bridge name bridge id STP enabled interfaces br-5bc39396abe2 8000.024219350061 no veth1a289de veth3504d23 docker0 8000.0242d50f88b5 no veth210c0a2 ... [root@rbtnode1 ~]# ip ad | grep veth 16: vethwe-datapath@vethwe-bridge: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1376 qdisc noqueue master datapath state UP group default 17: vethwe-bridge@vethwe-datapath: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1376 qdisc noqueue master weave state UP group default 2631: veth210c0a2@if2630: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master docker0 state UP group default 2682: veth3504d23@if2681: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master br-5bc39396abe2 state UP group default ##这里可以看到我们宿主机存在一个虚拟网卡 veth3504d23 ，他一端连接的是docker0，另一端则连接的是容器的eth0 ##其他的容器在创建的时候也会发生同样的事 ##相当于启动容器后，会有一“网线”，连接docker0和容器，由于都连接同一个交换机，默认情况下，各个容器间可以直接互通 容器的通信示意图（源自张磊）：k8s网络的发展 在docker的默认配置下，容器的网络没法处理跨主机网络的互相通信。为了解决跨主机通信的问题，社区出现了一些方案 flannel UDP 模式 而 UDP 模式，是 Flannel 项目最早支持的一种方式，也是性能最差的一种模式，如今已被弃用，但是对我们理解集群的网络还是有帮助的 该模式的主要通信过程如下"><meta itemprop=datePublished content="2019-10-11T15:52:55+00:00"><meta itemprop=dateModified content="2019-10-11T15:52:55+00:00"><meta itemprop=wordCount content="358"><meta itemprop=keywords content><meta name=twitter:card content="summary"><meta name=twitter:title content="k8s网络小探"><meta name=twitter:description content="容器网络 在说k8s的网络之前，先熟悉下容器的网络模式。
 docker会在宿主机启动一张网卡 docker0 容器通过Veth Pair 连接容器和docker0，Veth Pair相当于网线 docker0 在容器通信的过程中相当于二层交换机 容器会有默认路由指向docker0 当一个容器试图连接到另外一个宿主机时，首先经过 docker0 网桥出现在宿主机上。然后根据宿主机路由规则路由  #使用以下命令查看网桥的连接情况 [root@rbtnode1 ~]# brctl show bridge name bridge id STP enabled interfaces br-5bc39396abe2 8000.024219350061 no veth1a289de veth3504d23 docker0 8000.0242d50f88b5 no veth210c0a2 ... [root@rbtnode1 ~]# ip ad | grep veth 16: vethwe-datapath@vethwe-bridge: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1376 qdisc noqueue master datapath state UP group default 17: vethwe-bridge@vethwe-datapath: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1376 qdisc noqueue master weave state UP group default 2631: veth210c0a2@if2630: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master docker0 state UP group default 2682: veth3504d23@if2681: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master br-5bc39396abe2 state UP group default ##这里可以看到我们宿主机存在一个虚拟网卡 veth3504d23 ，他一端连接的是docker0，另一端则连接的是容器的eth0 ##其他的容器在创建的时候也会发生同样的事 ##相当于启动容器后，会有一“网线”，连接docker0和容器，由于都连接同一个交换机，默认情况下，各个容器间可以直接互通 容器的通信示意图（源自张磊）：k8s网络的发展 在docker的默认配置下，容器的网络没法处理跨主机网络的互相通信。为了解决跨主机通信的问题，社区出现了一些方案 flannel UDP 模式 而 UDP 模式，是 Flannel 项目最早支持的一种方式，也是性能最差的一种模式，如今已被弃用，但是对我们理解集群的网络还是有帮助的 该模式的主要通信过程如下"></head><body class="ma0 avenir bg-near-white"><header><div class=bg-black><nav class="pv3 ph3 ph4-ns" role=navigation><div class="flex-l justify-between items-center center"><a href=dingtalk.pub/ class="f3 fw2 hover-white no-underline white-90 dib">snoopy</a><div class="flex-l items-center"></div></div></nav></div></header><main class=pb7 role=main><article class="flex-l flex-wrap justify-between mw8 center ph3"><header class="mt4 w-100"><aside class="instapaper_ignoref b helvetica tracked">POSTS</aside><div id=sharing class=mt3><a href="https://www.facebook.com/sharer.php?u=dingtalk.pub/dingtalk.pub/post/2809327/" class="facebook no-underline" aria-label="share on Facebook"><svg height="32" style="enable-background:new 0 0 67 67" viewBox="0 0 67 67" width="32" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M28.765 50.32h6.744V33.998h4.499l.596-5.624h-5.095l.007-2.816c0-1.466.14-2.253 2.244-2.253h2.812V17.68h-4.5c-5.405.0-7.307 2.729-7.307 7.317v3.377h-3.369v5.625h3.369V50.32zM33 64C16.432 64 3 50.569 3 34S16.432 4 33 4s30 13.431 30 30S49.568 64 33 64z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg></a><a href="https://twitter.com/share?url=dingtalk.pub/dingtalk.pub/post/2809327/&text=k8s%e7%bd%91%e7%bb%9c%e5%b0%8f%e6%8e%a2" class="twitter no-underline" aria-label="share on Twitter"><svg height="32" style="enable-background:new 0 0 67 67" viewBox="0 0 67 67" width="32" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M37.167 22.283c-2.619.953-4.274 3.411-4.086 6.101l.063 1.038-1.048-.127c-3.813-.487-7.145-2.139-9.974-4.915l-1.383-1.377-.356 1.017c-.754 2.267-.272 4.661 1.299 6.271.838.89.649 1.017-.796.487-.503-.169-.943-.296-.985-.233-.146.149.356 2.076.754 2.839.545 1.06 1.655 2.097 2.871 2.712l1.027.487-1.215.021c-1.173.0-1.215.021-1.089.467.419 1.377 2.074 2.839 3.918 3.475l1.299.444-1.131.678c-1.676.976-3.646 1.526-5.616 1.568C19.775 43.256 19 43.341 19 43.405c0 .211 2.557 1.397 4.044 1.864 4.463 1.377 9.765.783 13.746-1.568 2.829-1.673 5.657-5 6.978-8.221.713-1.716 1.425-4.851 1.425-6.354.0-.975.063-1.102 1.236-2.267.692-.678 1.341-1.419 1.467-1.631.21-.403.188-.403-.88-.043-1.781.636-2.033.551-1.152-.402.649-.678 1.425-1.907 1.425-2.267.0-.063-.314.042-.671.233-.377.212-1.215.53-1.844.72l-1.131.361-1.027-.7c-.566-.381-1.361-.805-1.781-.932C39.766 21.902 38.131 21.944 37.167 22.283zM33 64C16.432 64 3 50.569 3 34S16.432 4 33 4s30 13.431 30 30S49.568 64 33 64z" style="fill-rule:evenodd;clip-rule:evenodd;fill:"/></svg></a><a href="https://www.linkedin.com/shareArticle?mini=true&url=dingtalk.pub/dingtalk.pub/post/2809327/&title=k8s%e7%bd%91%e7%bb%9c%e5%b0%8f%e6%8e%a2" class="linkedin no-underline" aria-label="share on LinkedIn"><svg height="32" style="enable-background:new 0 0 65 65" viewBox="0 0 65 65" width="32" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M50.837 48.137V36.425c0-6.275-3.35-9.195-7.816-9.195-3.604.0-5.219 1.983-6.119 3.374V27.71h-6.79c.09 1.917.0 20.427.0 20.427h6.79V36.729c0-.609.044-1.219.224-1.655.49-1.22 1.607-2.483 3.482-2.483 2.458.0 3.44 1.873 3.44 4.618v10.929H50.837zM22.959 24.922c2.367.0 3.842-1.57 3.842-3.531-.044-2.003-1.475-3.528-3.797-3.528s-3.841 1.524-3.841 3.528c0 1.961 1.474 3.531 3.753 3.531H22.959zM34 64C17.432 64 4 50.568 4 34 4 17.431 17.432 4 34 4s30 13.431 30 30c0 16.568-13.432 30-30 30zM26.354 48.137V27.71h-6.789v20.427h6.789z" style="fill-rule:evenodd;clip-rule:evenodd;fill:"/></svg></a></div><h1 class="f1 athelas mt3 mb1">k8s网络小探</h1><time class="f6 mv4 dib tracked" datetime=2019-10-11T15:52:55Z>October 11, 2019</time></header><div class="nested-copy-line-height lh-copy serif f4 nested-links nested-img mid-gray pr4-l w-two-thirds-l"><p></p><h2 id=容器网络>容器网络</h2><p>在说k8s的网络之前，先熟悉下容器的网络模式。</p><ul><li>docker会在宿主机启动一张网卡 docker0</li><li>容器通过Veth Pair 连接容器和docker0，Veth Pair相当于网线</li><li>docker0 在容器通信的过程中相当于二层交换机</li><li>容器会有默认路由指向docker0</li><li>当一个容器试图连接到另外一个宿主机时，首先经过 docker0 网桥出现在宿主机上。然后根据宿主机路由规则路由</li></ul><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=color:#75715e>#使用以下命令查看网桥的连接情况</span>
<span style=color:#f92672>[</span>root@rbtnode1 ~<span style=color:#f92672>]</span><span style=color:#75715e># brctl show</span>
bridge name     bridge id               STP enabled     interfaces
br-5bc39396abe2         8000.024219350061       no              veth1a289de
                                                        veth3504d23
docker0         8000.0242d50f88b5       no              veth210c0a2
...
<span style=color:#f92672>[</span>root@rbtnode1 ~<span style=color:#f92672>]</span><span style=color:#75715e># ip ad | grep veth</span>
16: vethwe-datapath@vethwe-bridge: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span style=color:#ae81ff>1376</span> qdisc noqueue master datapath state UP group default 
17: vethwe-bridge@vethwe-datapath: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span style=color:#ae81ff>1376</span> qdisc noqueue master weave state UP group default 
2631: veth210c0a2@if2630: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span style=color:#ae81ff>1500</span> qdisc noqueue master docker0 state UP group default 
2682: veth3504d23@if2681: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span style=color:#ae81ff>1500</span> qdisc noqueue master br-5bc39396abe2 state UP group default 
<span style=color:#75715e>##这里可以看到我们宿主机存在一个虚拟网卡 veth3504d23 ，他一端连接的是docker0，另一端则连接的是容器的eth0</span>
<span style=color:#75715e>##其他的容器在创建的时候也会发生同样的事</span>
<span style=color:#75715e>##相当于启动容器后，会有一“网线”，连接docker0和容器，由于都连接同一个交换机，默认情况下，各个容器间可以直接互通</span>
</code></pre></div><p>容器的通信示意图（源自张磊）：<img src=/images/2809327_1.png alt></p><h2 id=k8s网络的发展>k8s网络的发展</h2><p>在docker的默认配置下，容器的网络没法处理跨主机网络的互相通信。为了解决跨主机通信的问题，社区出现了一些方案</p><h3 id=flannel-udp-模式>flannel UDP  模式</h3><p>而 UDP 模式，是 Flannel 项目最早支持的一种方式，也是性能最差的一种模式，如今已被弃用，但是对我们理解集群的网络还是有帮助的 </p><p>该模式的主要通信过程如下</p><ol><li>容器A需要发送一个数据包到B(用户态)</li><li>首先还是会到docker0网口（<strong>用户态->内核态</strong>）</li><li>flannel在运行的时候会在宿主机创建一系列的路由规则(xx.xx.xx.xx/16 dev  flannel0，前提是docker0的网桥网段范围由flannel控制，dockerd启动的时候添加参数即可，FLANNEL_SUBNET=100.96.1.1/24 dockerd &ndash;bip=$FLANNEL_SUBNET ）</li><li>A需要访问的网段，会走宿主机的路由，他的下一跳是flannel0（内核态）</li><li>flannel0这里会把数据包交给应用程序 flanneld:8125 （<strong>内核态->用户态</strong>）</li><li>flanneld 进行 UDP 封包之后重新进入内核态，将udp的包通过宿主机的发出去（<strong>用户态->内核态</strong>）</li></ol><p>UDP模式示意图（源自张磊）：<img src=/images/2809327_2.png alt>UDP模式内核、用户态示意图（源自张磊）：<img src=/images/2809327_3.png alt>可以看出该模式仅在ip包发出的过程中，就需要经过三次用户态与内核态之间的数据拷贝，这个代价是比较高的，所以被弃用</p><h3 id=flannel-vxlan-模式>flannel VXLAN 模式</h3><p>Virtual Extensible LAN（虚拟可扩展局域网），VXLAN可以完全在内核态完成上述的封装和解封过程，大大提升了性能。VXLAN旨在在前的3层网络之上“覆盖”一层虚拟的，由vxlan内核模块负责的二层网络，以支持弹性计算结构；使得连接在这个VXLAN二层网络上的主机（虚拟机或者容器都行），可以像在同一个局域网（LAN）内自由连通,即使这些主机在不同的物理机上。VXLAN Tunnel End Point（虚拟隧道端点），VXLAN在宿主机建立的虚拟网络设备，作用是对二层数据帧（Ethernet frame）数据进行封装和解封  为了封装以太网帧，VTEP添加了许多字段，包括以下字段：</p><ul><li>外部媒体访问控制（MAC）目标地址（隧道端点VTEP的MAC地址）</li><li>外部MAC源地址（隧道源VTEP的MAC地址）</li><li>外部IP目标地址（隧道端点VTEP的IP地址）</li><li>外部IP源地址（隧道源VTEP的IP地址）</li><li>外部UDP标头</li><li>VXLAN标头包含一个24位字段（称为_VXLAN网络标识符（VNI））_，用于唯一标识VXLAN。VNI与VLAN ID相似，但是具有24位允许您创建比VLAN多得多的VXLAN。</li></ul><p>在这种模式下，数据包的流转依然需要经过flanneld，但是处理机制不同了   containers->docker0->flannel.1->eth0 基于VTEP设备进行通信的示意图：  <img src=/images/2809327_4.png alt>  1. 图中每台宿主机上名叫 flannel.1 的设备，就是 VXLAN 所需的 VTEP 设备，它既有 IP 地址，也有 MAC 地址。</p><ol start=2><li>现在，我们的 container-1 的 IP 地址是 10.1.15.2，要访问的 container-2 的 IP 地址是 10.1.16.3。 </li><li>flannel在运行的时候会在宿主机创建一系列的路由规则(xx.xx.xx.xx/24 dev  flannel.1）</li><li>为了能够将“原始 IP 包”封装并且发送到正确的宿主机，VXLAN 就需要找到这条“隧道”的出口，即：目的宿主机的 VTEP 设备->给这个原始数据包加上目的MAC（二层封装）</li><li>那么这个目的MAC的地址是什么呢，前面说道VTEP设备有ip和MAC，那么有ip想知道MAC就是ARP实现的东西了，在VTEP创建好后，会在自己的ARP表中记录，ip neigh show dev flannel.1 可以看到</li></ol><p>初步封包如下：<img src=/images/2809327_5.png alt></p><ol start=6><li>但是，上面提到的这些 VTEP 设备的 MAC 地址，对于宿主机网络来说并没有什么实际意义。所以上面封装出来的这个数据帧，并不能在我们的宿主机二层网络里传输。为了方便叙述，我们把它称为“内部数据帧”（Inner Ethernet Frame）。</li><li>所以接下来，Linux 内核还需要再把“内部数据帧”进一步封装成为宿主机网络里的一个普通的数据帧，好让它“载着”“内部数据帧”，通过宿主机的 eth0 网卡进行传输。</li><li>我们把这次要封装出来的、宿主机对应的数据帧称为“外部数据帧”（Outer Ethernet Frame）。</li><li>Linux 内核会在“内部数据帧”前面，加上一个特殊的 VXLAN 头，用来表示这个实际上是一个 VXLAN 要使用的数据帧。</li><li>而这个 VXLAN 头里有一个重要的标志叫作VNI,，它是 VTEP 设备识别某个数据帧是不是应该归自己处理的重要标识。而在 Flannel 中，VNI 的默认值是 1，这也是为何，宿主机上的 VTEP 设备都叫作 flannel.1 的原因，这里的“1”，其实就是 VNI 的值。</li><li>然后，Linux 内核会把这个数据帧封装进一个 UDP 包里发出去。</li><li>不过，一个 flannel.1 设备只知道另一端的 flannel.1 设备的 MAC 地址，却不知道对应的宿主机地址是什么。</li><li>在这种场景下，flannel.1 设备实际上要扮演一个“网桥”的角色，在二层网络进行 UDP 包的转发。而在 Linux 内核里面，“网桥”设备进行转发的依据，来自于一个叫作 FDB（Forwarding Database）的转发数据库。</li><li>这个 flannel.1“网桥”对应的 FDB 信息，也是 flanneld 进程负责维护的。它的内容可以通过 bridge fdb 命令查看到，如下所示：</li></ol><pre><code># 在 Node 1 上，使用“目的 VTEP 设备”的 MAC 地址进行查询
$ bridge fdb show flannel.1 | grep 5e:f8:4f:00:e3:37
5e:f8:4f:00:e3:37 dev flannel.1 dst 10.168.0.3 self permanent

</code></pre><p>这样udp的目的地就有了</p><ol start=15><li>UDP 包是一个四层数据包，所以 Linux 内核会在它前面加上一个 IP 头，即原理图中的 Outer IP Header，组成一个 IP 包。并且，在这个 IP 头里，会填上前面通过 FDB 查询出来的目的主机的 IP 地址，即 Node 2 的 IP 地址 10.168.0.3。</li><li>最后，Linux 内核再在这个 IP 包前面加上二层数据帧头，即原理图中的 Outer Ethernet Header，并把 Node 2 的 MAC 地址填进去。这个 MAC 地址本身，是 Node 1 的 ARP 表要学习的内容，无需 Flannel 维护。这时候，我们封装出来的“外部数据帧”的格式，如下所示（张磊图）：<img src=/images/2809327_6.png alt></li></ol><p>另外一个示意图：<img src=/images/2809327_7.png alt></p><ol start=17><li>接下来，Node 1 上的 flannel.1 设备就可以把这个数据帧从 Node 1 的 eth0 网卡发出去。显然，这个帧会经过宿主机网络来到 Node 2 的 eth0 网卡。这时候，Node 2 的内核网络栈会发现这个数据帧里有 VXLAN Header，并且 VNI=1。所以 Linux 内核会对它进行拆包，拿到里面的内部数据帧，然后根据 VNI 的值，把它交给 Node 2 上的 flannel.1 设备。而 flannel.1 设备则会进一步拆包，取出“原始 IP 包”。接下来就回到了我在前面提到的单机容器网络的处理流程。最终，IP 包就进入到了 container-2 容器的 Network Namespace 里。</li></ol><ul class=pa0></ul><div class="mt6 instapaper_ignoref"></div></div><aside class="w-30-l mt6-l"></aside></article></main><footer class="bg-black bottom-0 w-100 pa3" role=contentinfo><div class="flex justify-between"><a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href=dingtalk.pub>&copy; snoopy 2021</a><div></div></div></footer></body></html>
<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>k8s网络小探 | My New Hugo Site</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="容器网络 在说k8s的网络之前，先熟悉下容器的网络模式。
 docker会在宿主机启动一张网卡 docker0 容器通过Veth Pair 连接容器和docker0，Veth Pair相当于网线 docker0 在容器通信的过程中相当于二层交换机 容器会有默认路由指向docker0 当一个容器试图连接到另外一个宿主机时，首先经过 docker0 网桥出现在宿主机上。然后根据宿主机路由规则路由  #使用以下命令查看网桥的连接情况 [root@rbtnode1 ~]# brctl show bridge name bridge id STP enabled interfaces br-5bc39396abe2 8000.024219350061 no veth1a289de veth3504d23 docker0 8000.0242d50f88b5 no veth210c0a2 ... [root@rbtnode1 ~]# ip ad | grep veth 16: vethwe-datapath@vethwe-bridge: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1376 qdisc noqueue master datapath state UP group default 17: vethwe-bridge@vethwe-datapath: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1376 qdisc noqueue master weave state UP group default 2631: veth210c0a2@if2630: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master docker0 state UP group default 2682: veth3504d23@if2681: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master br-5bc39396abe2 state UP group default ##这里可以看到我们宿主机存在一个虚拟网卡 veth3504d23 ，他一端连接的是docker0，另一端则连接的是容器的eth0 ##其他的容器在创建的时候也会发生同样的事 ##相当于启动容器后，会有一“网线”，连接docker0和容器，由于都连接同一个交换机，默认情况下，各个容器间可以直接互通 容器的通信示意图（源自张磊）：k8s网络的发展 在docker的默认配置下，容器的网络没法处理跨主机网络的互相通信。为了解决跨主机通信的问题，社区出现了一些方案 flannel UDP 模式 而 UDP 模式，是 Flannel 项目最早支持的一种方式，也是性能最差的一种模式，如今已被弃用，但是对我们理解集群的网络还是有帮助的 该模式的主要通信过程如下">
    <meta name="generator" content="Hugo 0.83.1" />
    
    
      <META NAME="ROBOTS" CONTENT="NOINDEX, NOFOLLOW">
    

    

  
  
    <link rel="stylesheet" href="/ananke/dist/main.css_5c99d70a7725bacd4c701e995b969fea.css" >
  




    
      

    

    
    
    <meta property="og:title" content="k8s网络小探" />
<meta property="og:description" content="容器网络 在说k8s的网络之前，先熟悉下容器的网络模式。
 docker会在宿主机启动一张网卡 docker0 容器通过Veth Pair 连接容器和docker0，Veth Pair相当于网线 docker0 在容器通信的过程中相当于二层交换机 容器会有默认路由指向docker0 当一个容器试图连接到另外一个宿主机时，首先经过 docker0 网桥出现在宿主机上。然后根据宿主机路由规则路由  #使用以下命令查看网桥的连接情况 [root@rbtnode1 ~]# brctl show bridge name bridge id STP enabled interfaces br-5bc39396abe2 8000.024219350061 no veth1a289de veth3504d23 docker0 8000.0242d50f88b5 no veth210c0a2 ... [root@rbtnode1 ~]# ip ad | grep veth 16: vethwe-datapath@vethwe-bridge: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1376 qdisc noqueue master datapath state UP group default 17: vethwe-bridge@vethwe-datapath: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1376 qdisc noqueue master weave state UP group default 2631: veth210c0a2@if2630: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master docker0 state UP group default 2682: veth3504d23@if2681: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master br-5bc39396abe2 state UP group default ##这里可以看到我们宿主机存在一个虚拟网卡 veth3504d23 ，他一端连接的是docker0，另一端则连接的是容器的eth0 ##其他的容器在创建的时候也会发生同样的事 ##相当于启动容器后，会有一“网线”，连接docker0和容器，由于都连接同一个交换机，默认情况下，各个容器间可以直接互通 容器的通信示意图（源自张磊）：k8s网络的发展 在docker的默认配置下，容器的网络没法处理跨主机网络的互相通信。为了解决跨主机通信的问题，社区出现了一些方案 flannel UDP 模式 而 UDP 模式，是 Flannel 项目最早支持的一种方式，也是性能最差的一种模式，如今已被弃用，但是对我们理解集群的网络还是有帮助的 该模式的主要通信过程如下" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://example.org/post/2809327/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2019-10-11T15:52:55&#43;00:00" />
<meta property="article:modified_time" content="2019-10-11T15:52:55&#43;00:00" />

<meta itemprop="name" content="k8s网络小探">
<meta itemprop="description" content="容器网络 在说k8s的网络之前，先熟悉下容器的网络模式。
 docker会在宿主机启动一张网卡 docker0 容器通过Veth Pair 连接容器和docker0，Veth Pair相当于网线 docker0 在容器通信的过程中相当于二层交换机 容器会有默认路由指向docker0 当一个容器试图连接到另外一个宿主机时，首先经过 docker0 网桥出现在宿主机上。然后根据宿主机路由规则路由  #使用以下命令查看网桥的连接情况 [root@rbtnode1 ~]# brctl show bridge name bridge id STP enabled interfaces br-5bc39396abe2 8000.024219350061 no veth1a289de veth3504d23 docker0 8000.0242d50f88b5 no veth210c0a2 ... [root@rbtnode1 ~]# ip ad | grep veth 16: vethwe-datapath@vethwe-bridge: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1376 qdisc noqueue master datapath state UP group default 17: vethwe-bridge@vethwe-datapath: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1376 qdisc noqueue master weave state UP group default 2631: veth210c0a2@if2630: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master docker0 state UP group default 2682: veth3504d23@if2681: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master br-5bc39396abe2 state UP group default ##这里可以看到我们宿主机存在一个虚拟网卡 veth3504d23 ，他一端连接的是docker0，另一端则连接的是容器的eth0 ##其他的容器在创建的时候也会发生同样的事 ##相当于启动容器后，会有一“网线”，连接docker0和容器，由于都连接同一个交换机，默认情况下，各个容器间可以直接互通 容器的通信示意图（源自张磊）：k8s网络的发展 在docker的默认配置下，容器的网络没法处理跨主机网络的互相通信。为了解决跨主机通信的问题，社区出现了一些方案 flannel UDP 模式 而 UDP 模式，是 Flannel 项目最早支持的一种方式，也是性能最差的一种模式，如今已被弃用，但是对我们理解集群的网络还是有帮助的 该模式的主要通信过程如下"><meta itemprop="datePublished" content="2019-10-11T15:52:55&#43;00:00" />
<meta itemprop="dateModified" content="2019-10-11T15:52:55&#43;00:00" />
<meta itemprop="wordCount" content="358">
<meta itemprop="keywords" content="" /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="k8s网络小探"/>
<meta name="twitter:description" content="容器网络 在说k8s的网络之前，先熟悉下容器的网络模式。
 docker会在宿主机启动一张网卡 docker0 容器通过Veth Pair 连接容器和docker0，Veth Pair相当于网线 docker0 在容器通信的过程中相当于二层交换机 容器会有默认路由指向docker0 当一个容器试图连接到另外一个宿主机时，首先经过 docker0 网桥出现在宿主机上。然后根据宿主机路由规则路由  #使用以下命令查看网桥的连接情况 [root@rbtnode1 ~]# brctl show bridge name bridge id STP enabled interfaces br-5bc39396abe2 8000.024219350061 no veth1a289de veth3504d23 docker0 8000.0242d50f88b5 no veth210c0a2 ... [root@rbtnode1 ~]# ip ad | grep veth 16: vethwe-datapath@vethwe-bridge: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1376 qdisc noqueue master datapath state UP group default 17: vethwe-bridge@vethwe-datapath: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1376 qdisc noqueue master weave state UP group default 2631: veth210c0a2@if2630: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master docker0 state UP group default 2682: veth3504d23@if2681: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master br-5bc39396abe2 state UP group default ##这里可以看到我们宿主机存在一个虚拟网卡 veth3504d23 ，他一端连接的是docker0，另一端则连接的是容器的eth0 ##其他的容器在创建的时候也会发生同样的事 ##相当于启动容器后，会有一“网线”，连接docker0和容器，由于都连接同一个交换机，默认情况下，各个容器间可以直接互通 容器的通信示意图（源自张磊）：k8s网络的发展 在docker的默认配置下，容器的网络没法处理跨主机网络的互相通信。为了解决跨主机通信的问题，社区出现了一些方案 flannel UDP 模式 而 UDP 模式，是 Flannel 项目最早支持的一种方式，也是性能最差的一种模式，如今已被弃用，但是对我们理解集群的网络还是有帮助的 该模式的主要通信过程如下"/>

	
  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  <header>
    <div class="bg-black">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="/" class="f3 fw2 hover-white no-underline white-90 dib">
      
        My New Hugo Site
      
    </a>
    <div class="flex-l items-center">
      

      
      















    </div>
  </div>
</nav>

    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref b helvetica tracked">
          
        POSTS
      </aside>
      




  <div id="sharing" class="mt3">

    
    <a href="https://www.facebook.com/sharer.php?u=http://example.org/post/2809327/" class="facebook no-underline" aria-label="share on Facebook">
      <svg height="32px"  style="enable-background:new 0 0 67 67;" version="1.1" viewBox="0 0 67 67" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M28.765,50.32h6.744V33.998h4.499l0.596-5.624h-5.095  l0.007-2.816c0-1.466,0.14-2.253,2.244-2.253h2.812V17.68h-4.5c-5.405,0-7.307,2.729-7.307,7.317v3.377h-3.369v5.625h3.369V50.32z   M33,64C16.432,64,3,50.569,3,34S16.432,4,33,4s30,13.431,30,30S49.568,64,33,64z" style="fill-rule:evenodd;clip-rule:evenodd;"/></svg>

    </a>

    
    
    <a href="https://twitter.com/share?url=http://example.org/post/2809327/&amp;text=k8s%e7%bd%91%e7%bb%9c%e5%b0%8f%e6%8e%a2" class="twitter no-underline" aria-label="share on Twitter">
      <svg height="32px"  style="enable-background:new 0 0 67 67;" version="1.1" viewBox="0 0 67 67" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M37.167,22.283c-2.619,0.953-4.274,3.411-4.086,6.101  l0.063,1.038l-1.048-0.127c-3.813-0.487-7.145-2.139-9.974-4.915l-1.383-1.377l-0.356,1.017c-0.754,2.267-0.272,4.661,1.299,6.271  c0.838,0.89,0.649,1.017-0.796,0.487c-0.503-0.169-0.943-0.296-0.985-0.233c-0.146,0.149,0.356,2.076,0.754,2.839  c0.545,1.06,1.655,2.097,2.871,2.712l1.027,0.487l-1.215,0.021c-1.173,0-1.215,0.021-1.089,0.467  c0.419,1.377,2.074,2.839,3.918,3.475l1.299,0.444l-1.131,0.678c-1.676,0.976-3.646,1.526-5.616,1.568  C19.775,43.256,19,43.341,19,43.405c0,0.211,2.557,1.397,4.044,1.864c4.463,1.377,9.765,0.783,13.746-1.568  c2.829-1.673,5.657-5,6.978-8.221c0.713-1.716,1.425-4.851,1.425-6.354c0-0.975,0.063-1.102,1.236-2.267  c0.692-0.678,1.341-1.419,1.467-1.631c0.21-0.403,0.188-0.403-0.88-0.043c-1.781,0.636-2.033,0.551-1.152-0.402  c0.649-0.678,1.425-1.907,1.425-2.267c0-0.063-0.314,0.042-0.671,0.233c-0.377,0.212-1.215,0.53-1.844,0.72l-1.131,0.361l-1.027-0.7  c-0.566-0.381-1.361-0.805-1.781-0.932C39.766,21.902,38.131,21.944,37.167,22.283z M33,64C16.432,64,3,50.569,3,34S16.432,4,33,4  s30,13.431,30,30S49.568,64,33,64z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/></svg>

    </a>

    
    <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http://example.org/post/2809327/&amp;title=k8s%e7%bd%91%e7%bb%9c%e5%b0%8f%e6%8e%a2" class="linkedin no-underline" aria-label="share on LinkedIn">
      <svg  height="32px"  style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>

    </a>
  </div>


      <h1 class="f1 athelas mt3 mb1">k8s网络小探</h1>
      
      
      <time class="f6 mv4 dib tracked" datetime="2019-10-11T15:52:55Z">October 11, 2019</time>

      
      
    </header>
    <div class="nested-copy-line-height lh-copy serif f4 nested-links nested-img mid-gray pr4-l w-two-thirds-l"><p><!-- raw HTML omitted --><!-- raw HTML omitted --></p>
<h2 id="容器网络">容器网络</h2>
<p>在说k8s的网络之前，先熟悉下容器的网络模式。</p>
<ul>
<li>docker会在宿主机启动一张网卡 docker0</li>
<li>容器通过Veth Pair 连接容器和docker0，Veth Pair相当于网线</li>
<li>docker0 在容器通信的过程中相当于二层交换机</li>
<li>容器会有默认路由指向docker0</li>
<li>当一个容器试图连接到另外一个宿主机时，首先经过 docker0 网桥出现在宿主机上。然后根据宿主机路由规则路由</li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"><span style="color:#75715e">#使用以下命令查看网桥的连接情况</span>
<span style="color:#f92672">[</span>root@rbtnode1 ~<span style="color:#f92672">]</span><span style="color:#75715e"># brctl show</span>
bridge name     bridge id               STP enabled     interfaces
br-5bc39396abe2         8000.024219350061       no              veth1a289de
                                                        veth3504d23
docker0         8000.0242d50f88b5       no              veth210c0a2
...
<span style="color:#f92672">[</span>root@rbtnode1 ~<span style="color:#f92672">]</span><span style="color:#75715e"># ip ad | grep veth</span>
16: vethwe-datapath@vethwe-bridge: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span style="color:#ae81ff">1376</span> qdisc noqueue master datapath state UP group default 
17: vethwe-bridge@vethwe-datapath: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span style="color:#ae81ff">1376</span> qdisc noqueue master weave state UP group default 
2631: veth210c0a2@if2630: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span style="color:#ae81ff">1500</span> qdisc noqueue master docker0 state UP group default 
2682: veth3504d23@if2681: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span style="color:#ae81ff">1500</span> qdisc noqueue master br-5bc39396abe2 state UP group default 
<span style="color:#75715e">##这里可以看到我们宿主机存在一个虚拟网卡 veth3504d23 ，他一端连接的是docker0，另一端则连接的是容器的eth0</span>
<span style="color:#75715e">##其他的容器在创建的时候也会发生同样的事</span>
<span style="color:#75715e">##相当于启动容器后，会有一“网线”，连接docker0和容器，由于都连接同一个交换机，默认情况下，各个容器间可以直接互通</span>
</code></pre></div><p>容器的通信示意图（源自张磊）：<!-- raw HTML omitted --><img src="/images/2809327_1.png" alt="">
<!-- raw HTML omitted --><!-- raw HTML omitted --></p>
<h2 id="k8s网络的发展">k8s网络的发展</h2>
<p>在docker的默认配置下，容器的网络没法处理跨主机网络的互相通信。为了解决跨主机通信的问题，社区出现了一些方案
<!-- raw HTML omitted --><!-- raw HTML omitted --></p>
<h3 id="flannel-udp-模式">flannel UDP  模式</h3>
<p>而 UDP 模式，是 Flannel 项目最早支持的一种方式，也是性能最差的一种模式，如今已被弃用，但是对我们理解集群的网络还是有帮助的 </p>
<p>该模式的主要通信过程如下</p>
<ol>
<li>容器A需要发送一个数据包到B(用户态)</li>
<li>首先还是会到docker0网口（<strong>用户态-&gt;内核态</strong>）</li>
<li>flannel在运行的时候会在宿主机创建一系列的路由规则(xx.xx.xx.xx/16 dev  flannel0，前提是docker0的网桥网段范围由flannel控制，dockerd启动的时候添加参数即可，FLANNEL_SUBNET=100.96.1.1/24 dockerd &ndash;bip=$FLANNEL_SUBNET ）</li>
<li>A需要访问的网段，会走宿主机的路由，他的下一跳是flannel0（内核态）</li>
<li>flannel0这里会把数据包交给应用程序 flanneld:8125 （<strong>内核态-&gt;用户态</strong>）</li>
<li>flanneld 进行 UDP 封包之后重新进入内核态，将udp的包通过宿主机的发出去（<strong>用户态-&gt;内核态</strong>）</li>
</ol>
<p>UDP模式示意图（源自张磊）：<!-- raw HTML omitted --><img src="/images/2809327_2.png" alt=""><!-- raw HTML omitted -->UDP模式内核、用户态示意图（源自张磊）：<!-- raw HTML omitted --><img src="/images/2809327_3.png" alt=""><!-- raw HTML omitted -->可以看出该模式仅在ip包发出的过程中，就需要经过三次用户态与内核态之间的数据拷贝，这个代价是比较高的，所以被弃用
<!-- raw HTML omitted --><!-- raw HTML omitted --></p>
<h3 id="flannel-vxlan-模式">flannel VXLAN 模式</h3>
<p>Virtual Extensible LAN（虚拟可扩展局域网），VXLAN可以完全在内核态完成上述的封装和解封过程，大大提升了性能。<!-- raw HTML omitted -->VXLAN旨在在前的3层网络之上“覆盖”一层虚拟的，由vxlan内核模块负责的二层网络，以支持弹性计算结构；使得连接在这个VXLAN二层网络上的主机（虚拟机或者容器都行），可以像在同一个局域网（LAN）内自由连通,<!-- raw HTML omitted -->即使这些主机在不同的物理机上。<!-- raw HTML omitted -->VXLAN Tunnel End Point（虚拟隧道端点），VXLAN在宿主机建立的虚拟网络设备，作用是对二层数据帧（Ethernet frame）数据进行封装和解封  <!-- raw HTML omitted -->为了封装以太网帧，VTEP添加了许多字段，包括以下字段：</p>
<ul>
<li>外部媒体访问控制（MAC）目标地址（隧道端点VTEP的MAC地址）<!-- raw HTML omitted --></li>
<li>外部MAC源地址（隧道源VTEP的MAC地址）<!-- raw HTML omitted --></li>
<li>外部IP目标地址（隧道端点VTEP的IP地址）<!-- raw HTML omitted --></li>
<li>外部IP源地址（隧道源VTEP的IP地址）<!-- raw HTML omitted --></li>
<li>外部UDP标头<!-- raw HTML omitted --></li>
<li>VXLAN标头包含一个24位字段（称为_VXLAN网络标识符（VNI））_，用于唯一标识VXLAN。VNI与VLAN ID相似，但是具有24位允许您创建比VLAN多得多的VXLAN。<!-- raw HTML omitted --></li>
</ul>
<p>在这种模式下，数据包的流转依然需要经过flanneld，但是处理机制不同了   containers-&gt;docker0-&gt;flannel.1-&gt;eth0 <!-- raw HTML omitted -->基于VTEP设备进行通信的示意图：  <!-- raw HTML omitted --><img src="/images/2809327_4.png" alt="">  1. 图中每台宿主机上名叫 flannel.1 的设备，就是 VXLAN 所需的 VTEP 设备，它既有 IP 地址，也有 MAC 地址。</p>
<ol start="2">
<li>现在，我们的 container-1 的 IP 地址是 10.1.15.2，要访问的 container-2 的 IP 地址是 10.1.16.3。 </li>
<li>flannel在运行的时候会在宿主机创建一系列的路由规则(xx.xx.xx.xx/24 dev  flannel.1）</li>
<li>为了能够将“原始 IP 包”封装并且发送到正确的宿主机，VXLAN 就需要找到这条“隧道”的出口，即：目的宿主机的 VTEP 设备-&gt;给这个原始数据包加上目的MAC（二层封装）</li>
<li>那么这个目的MAC的地址是什么呢，前面说道VTEP设备有ip和MAC，那么有ip想知道MAC就是ARP实现的东西了，在VTEP创建好后，会在自己的ARP表中记录，ip neigh show dev flannel.1 可以看到</li>
</ol>
<p>初步封包如下：<!-- raw HTML omitted --><img src="/images/2809327_5.png" alt=""></p>
<ol start="6">
<li>但是，上面提到的这些 VTEP 设备的 MAC 地址，对于宿主机网络来说并没有什么实际意义。所以上面封装出来的这个数据帧，并不能在我们的宿主机二层网络里传输。为了方便叙述，我们把它称为“内部数据帧”（Inner Ethernet Frame）。</li>
<li>所以接下来，Linux 内核还需要再把“内部数据帧”进一步封装成为宿主机网络里的一个普通的数据帧，好让它“载着”“内部数据帧”，通过宿主机的 eth0 网卡进行传输。</li>
<li>我们把这次要封装出来的、宿主机对应的数据帧称为“外部数据帧”（Outer Ethernet Frame）。</li>
<li>Linux 内核会在“内部数据帧”前面，加上一个特殊的 VXLAN 头，用来表示这个实际上是一个 VXLAN 要使用的数据帧。</li>
<li>而这个 VXLAN 头里有一个重要的标志叫作VNI,，它是 VTEP 设备识别某个数据帧是不是应该归自己处理的重要标识。而在 Flannel 中，VNI 的默认值是 1，这也是为何，宿主机上的 VTEP 设备都叫作 flannel.1 的原因，这里的“1”，其实就是 VNI 的值。</li>
<li>然后，Linux 内核会把这个数据帧封装进一个 UDP 包里发出去。</li>
<li>不过，一个 flannel.1 设备只知道另一端的 flannel.1 设备的 MAC 地址，却不知道对应的宿主机地址是什么。</li>
<li>在这种场景下，flannel.1 设备实际上要扮演一个“网桥”的角色，在二层网络进行 UDP 包的转发。而在 Linux 内核里面，“网桥”设备进行转发的依据，来自于一个叫作 FDB（Forwarding Database）的转发数据库。</li>
<li>这个 flannel.1“网桥”对应的 FDB 信息，也是 flanneld 进程负责维护的。它的内容可以通过 bridge fdb 命令查看到，如下所示：</li>
</ol>
<pre><code># 在 Node 1 上，使用“目的 VTEP 设备”的 MAC 地址进行查询
$ bridge fdb show flannel.1 | grep 5e:f8:4f:00:e3:37
5e:f8:4f:00:e3:37 dev flannel.1 dst 10.168.0.3 self permanent

</code></pre><p>这样udp的目的地就有了</p>
<ol start="15">
<li>UDP 包是一个四层数据包，所以 Linux 内核会在它前面加上一个 IP 头，即原理图中的 Outer IP Header，组成一个 IP 包。并且，在这个 IP 头里，会填上前面通过 FDB 查询出来的目的主机的 IP 地址，即 Node 2 的 IP 地址 10.168.0.3。</li>
<li>最后，Linux 内核再在这个 IP 包前面加上二层数据帧头，即原理图中的 Outer Ethernet Header，并把 Node 2 的 MAC 地址填进去。这个 MAC 地址本身，是 Node 1 的 ARP 表要学习的内容，无需 Flannel 维护。这时候，我们封装出来的“外部数据帧”的格式，如下所示（张磊图）：<img src="/images/2809327_6.png" alt=""></li>
</ol>
<p>另外一个示意图：<img src="/images/2809327_7.png" alt=""></p>
<ol start="17">
<li>接下来，Node 1 上的 flannel.1 设备就可以把这个数据帧从 Node 1 的 eth0 网卡发出去。显然，这个帧会经过宿主机网络来到 Node 2 的 eth0 网卡。这时候，Node 2 的内核网络栈会发现这个数据帧里有 VXLAN Header，并且 VNI=1。所以 Linux 内核会对它进行拆包，拿到里面的内部数据帧，然后根据 VNI 的值，把它交给 Node 2 上的 flannel.1 设备。而 flannel.1 设备则会进一步拆包，取出“原始 IP 包”。接下来就回到了我在前面提到的单机容器网络的处理流程。最终，IP 包就进入到了 container-2 容器的 Network Namespace 里。</li>
</ol>
<ul class="pa0">
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="http://example.org/" >
    &copy;  My New Hugo Site 2021 
  </a>
    <div>














</div>
  </div>
</footer>

  </body>
</html>
